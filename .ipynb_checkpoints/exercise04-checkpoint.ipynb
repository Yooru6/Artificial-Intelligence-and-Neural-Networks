{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: NMIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name and student id: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import preprocessing,metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score,confusion_matrix,f1_score,classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True) # download takes a while \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize feature data and split the data into training and test sets with 30% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f1720ab7de24a6b27875d52c24c7f9e",
     "grade": false,
     "grade_id": "cell-209025c51cb01994",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 784)\n"
     ]
    }
   ],
   "source": [
    "# scaled_x = ...\n",
    "# x_train, x_test, y_train, y_test = ...\n",
    "# YOUR CODE HERE\n",
    "x=x/255\n",
    "\n",
    "###Define how many pictures use for training and testing###\n",
    "train_size = 3000\n",
    "test_size = 1000\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3 ) #train_size=train_size\n",
    "#raise NotImplementedError()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e86d3ce364edfedc4fef55df122fb13",
     "grade": true,
     "grade_id": "cell-12fbc75302e1add3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(x_train.shape == (49000, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree classifier model (assign to variable model) with default parameters. Compute training and test scores and assign them to training_score and test_score. Also print the confusion matrix for both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78373395063d18cd1b0057cd3e5f07fc",
     "grade": false,
     "grade_id": "cell-c003e2eba3246ea7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9621020408163266\n",
      "Predicted     0     1     2     3     4     5     6     7     8     9    All\n",
      "True                                                                        \n",
      "0          4748     1    14    11    12    15     8     3     9     2   4823\n",
      "1             1  5417    13     9     5    12     3     6    19     4   5489\n",
      "2            24    23  4746    25    18     9     8    11    22    13   4899\n",
      "3            29    22    44  4767     6    47     8    22    16     9   4970\n",
      "4            19     8    33    14  4679    11    14    12    20    28   4838\n",
      "5            32    17    27    62    40  4190    19    18    21    16   4442\n",
      "6            32    11    37     9    23    33  4642     2    12     1   4802\n",
      "7             9    17    32    30    35    12     4  4962    15    34   5150\n",
      "8            27    27    43    59    31    57    16    21  4477    16   4774\n",
      "9            27    15    29    39    77    29     7    51    24  4515   4813\n",
      "All        4948  5558  5018  5025  4926  4415  4729  5108  4635  4638  49000 \n",
      "\n",
      "Testing accuracy:  0.8606666666666667\n",
      "Predicted     0     1     2     3     4     5     6     7     8     9    All\n",
      "True                                                                        \n",
      "0          1940     1    29    19    14    17    20     6    19    15   2080\n",
      "1             3  2290    22    17     6    10     7     7    17     9   2388\n",
      "2            38    23  1801    50    32    26    31    31    43    16   2091\n",
      "3            31    33    63  1795    16   118     8    24    49    34   2171\n",
      "4            16     9    28    18  1696    28    23    19    46   103   1986\n",
      "5            40    21    19   112    32  1505    39    20    52    31   1871\n",
      "6            30    14    35    11    44    50  1847     5    31     7   2074\n",
      "7            12    16    46    25    58    14     4  1864    19    85   2143\n",
      "8            28    32    72    79    51    82    26    24  1599    58   2051\n",
      "9            18    11    23    48   115    42     5   103    43  1737   2145\n",
      "All        2156  2450  2138  2174  2064  1892  2010  2103  1918  2095  21000 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      2080\n",
      "           1       0.93      0.96      0.95      2388\n",
      "           2       0.84      0.86      0.85      2091\n",
      "           3       0.83      0.83      0.83      2171\n",
      "           4       0.82      0.85      0.84      1986\n",
      "           5       0.80      0.80      0.80      1871\n",
      "           6       0.92      0.89      0.90      2074\n",
      "           7       0.89      0.87      0.88      2143\n",
      "           8       0.83      0.78      0.81      2051\n",
      "           9       0.83      0.81      0.82      2145\n",
      "\n",
      "    accuracy                           0.86     21000\n",
      "   macro avg       0.86      0.86      0.86     21000\n",
      "weighted avg       0.86      0.86      0.86     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = ...\n",
    "# training_score = ...\n",
    "# test_score = ...\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "model =DecisionTreeClassifier(criterion=\"gini\",\n",
    "                             #min_samples_split=5,\n",
    "                             min_samples_leaf=3,\n",
    "                             #splitter='best',\n",
    "                             max_depth=150)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "preTR = model.predict(x_train)\n",
    "preTS = model.predict(x_test)\n",
    "\n",
    "training_score = metrics.accuracy_score(y_train, preTR)\n",
    "test_score = metrics.accuracy_score(y_test, preTS)\n",
    "\n",
    "print('Training accuracy: ',training_score)\n",
    "print(pd.crosstab(y_train, preTR, rownames=['True'], colnames=['Predicted'], margins=True),\"\\n\")\n",
    "\n",
    "\n",
    "print('Testing accuracy: ',test_score)\n",
    "print(pd.crosstab(y_test, preTS, rownames=['True'], colnames=['Predicted'], margins=True),\"\\n\")\n",
    "print(classification_report(y_test,preTS))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_samples_leaf = 2 overFit?\n",
    "depth:150\n",
    "acc=0.86<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3ec9cd762796a42669c0a829ebc0d69",
     "grade": true,
     "grade_id": "cell-4dd090649c9d931d",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(training_score, 1.0, decimal=1)\n",
    "np.testing.assert_almost_equal(test_score, 0.87, decimal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many times in validation set\n",
    "- digit 3 gets misclassified?\n",
    "- digit 4 gets misclassified as 7?\n",
    "\n",
    "What is the most misclassified digit?\n",
    "\n",
    "Please answer in cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e98e9711489f9b500be09ba3d93dce35",
     "grade": true,
     "grade_id": "cell-55c2755f23c8ffd9",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## YOUR ANSWER HERE\n",
    "digit 3 was miss classified: 31+33+63+16+118+8+24+49+34 = 376 times<br>\n",
    "digit 4 was missclassified as 7: 19 times<br>\n",
    "Most misclassified digit is number 5 score 80%<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a random forest classifier model (assigned to variable model) with default parameters. Compute training and test scores and assign them to training_score and test_score. Also print the confusion matrix for both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3809696e22fc69768848ceb1b5e1783",
     "grade": false,
     "grade_id": "cell-79b9eddba0cbcb28",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  1.0\n",
      "Predicted     0     1     2     3     4     5     6     7     8     9    All\n",
      "True                                                                        \n",
      "0          4823     0     0     0     0     0     0     0     0     0   4823\n",
      "1             0  5489     0     0     0     0     0     0     0     0   5489\n",
      "2             0     0  4899     0     0     0     0     0     0     0   4899\n",
      "3             0     0     0  4970     0     0     0     0     0     0   4970\n",
      "4             0     0     0     0  4838     0     0     0     0     0   4838\n",
      "5             0     0     0     0     0  4442     0     0     0     0   4442\n",
      "6             0     0     0     0     0     0  4802     0     0     0   4802\n",
      "7             0     0     0     0     0     0     0  5150     0     0   5150\n",
      "8             0     0     0     0     0     0     0     0  4774     0   4774\n",
      "9             0     0     0     0     0     0     0     0     0  4813   4813\n",
      "All        4823  5489  4899  4970  4838  4442  4802  5150  4774  4813  49000 \n",
      "\n",
      "Testing accuracy:  0.9671428571428572\n",
      "Predicted     0     1     2     3     4     5     6     7     8     9    All\n",
      "True                                                                        \n",
      "0          2058     0     2     1     1     3     7     1     6     1   2080\n",
      "1             0  2359    14     2     4     2     2     1     2     2   2388\n",
      "2            11     2  2030    13    11     0     2     7    15     0   2091\n",
      "3             1     1    38  2075     1    13     3    15    16     8   2171\n",
      "4             1     2     2     0  1932     1    13     2     5    28   1986\n",
      "5            11     1     4    24     4  1784    17     3     7    16   1871\n",
      "6             5     2     2     0     3     9  2047     0     6     0   2074\n",
      "7             2     5    29     2    21     1     1  2044     6    32   2143\n",
      "8             6    11    12    27    10    16     9     6  1929    25   2051\n",
      "9             6     1     3    23    28     7     0    19     6  2052   2145\n",
      "All        2101  2384  2136  2167  2015  1836  2101  2098  1998  2164  21000 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2080\n",
      "           1       0.99      0.99      0.99      2388\n",
      "           2       0.95      0.97      0.96      2091\n",
      "           3       0.96      0.96      0.96      2171\n",
      "           4       0.96      0.97      0.97      1986\n",
      "           5       0.97      0.95      0.96      1871\n",
      "           6       0.97      0.99      0.98      2074\n",
      "           7       0.97      0.95      0.96      2143\n",
      "           8       0.97      0.94      0.95      2051\n",
      "           9       0.95      0.96      0.95      2145\n",
      "\n",
      "    accuracy                           0.97     21000\n",
      "   macro avg       0.97      0.97      0.97     21000\n",
      "weighted avg       0.97      0.97      0.97     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = ...\n",
    "# training_score = ...\n",
    "# test_score = ...\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "model =RandomForestClassifier(criterion=\"gini\",\n",
    "                            # min_samples_split=100,\n",
    "                             #min_samples_leaf=50,\n",
    "                             \n",
    "                             max_depth=150)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "preTR = model.predict(x_train)\n",
    "preTS = model.predict(x_test)\n",
    "\n",
    "training_score = metrics.accuracy_score(y_train, preTR)\n",
    "test_score = metrics.accuracy_score(y_test, preTS)\n",
    "\n",
    "\n",
    "print('Training accuracy: ',training_score)\n",
    "print(pd.crosstab(y_train, preTR, rownames=['True'], colnames=['Predicted'], margins=True),\"\\n\")\n",
    "\n",
    "print('Testing accuracy: ',test_score)\n",
    "print(pd.crosstab(y_test, preTS, rownames=['True'], colnames=['Predicted'], margins=True),\"\\n\")\n",
    "print(classification_report(y_test,preTS))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depth:30\n",
    "acc=0.925<br>\n",
    "depth:40\n",
    "acc=0.924<br>\n",
    "depth:60\n",
    "acc=0.927<br>\n",
    "depth:100\n",
    "acc=0.966<br>\n",
    "depth:150\n",
    "acc=0.967<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10a7437f89e71f896c0b463b64cdfd7b",
     "grade": true,
     "grade_id": "cell-0d5a87fccfa891dc",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not almost equal to 2 decimals\n ACTUAL: 0.9671428571428572\n DESIRED: 0.944",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-ff77141e5202>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.944\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\u001b[0m in \u001b[0;36massert_almost_equal\u001b[1;34m(actual, desired, decimal, err_msg, verbose)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesired\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mactual\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_build_err_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nArrays are not almost equal to 2 decimals\n ACTUAL: 0.9671428571428572\n DESIRED: 0.944"
     ]
    }
   ],
   "source": [
    "np.testing.assert_almost_equal(training_score, 0.999, decimal=2)\n",
    "np.testing.assert_almost_equal(test_score, 0.944, decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
